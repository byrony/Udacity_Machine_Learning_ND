{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Udacity Machine Learning Nanodegree\n",
    "### Allstate Insurance Claims Prediction -- Capstone Proposal\n",
    "\n",
    "Xiang Cao\n",
    "\n",
    "10-10-2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain Background\n",
    "As a important domain of Machine Learning, supervised learning has a wide variety of applications in different areas including computer vision, natural language processing, recommendation system, credit risk prediction, etc. \n",
    "\n",
    "The essence of Machine Learning is to learn hidden pattern underneath data, data could be unstructured like image, language, or tabular data like stock trading data, customer behavior, etc., or a mixture of them. According to the pattern / knowledge it learnt, we can customize our product and service to people more accurately and efficiently. \n",
    "\n",
    "In finance/insurance area, there are large amount of user data, with which we can customize finance/insurance product to increase company revenue and improve user experience. Machine Learning provides promising methods to do this.\n",
    "\n",
    "### Problem Statement\n",
    "Allstate held a competition on Kaggle, which aims to develop automated method to predict insurance claims cost, and hence severity. The data includes the historical claims cost and customer information for each claim. In this project, I am going to predict claim cost using different machine learning models. \n",
    "\n",
    "### Datasets and Inputs\n",
    "The datasets are provided by Allstate on Kaggle. The training set has 188318 records and 132 columns, including unique ID, 116 categorical features, 14 continuous features, and target. All the features are anonymous. The testing set has 125546 rows and columns except target. In this project I split training set into training and validation to train and evalution models.\n",
    "\n",
    "### Solution Statement\n",
    "Multiple models are implemented in this project. Including regression, gradient boosting tree, neural network, etc.\n",
    "\n",
    "\n",
    "### Benchmark Model\n",
    "For each model with default or empirical parameter, we would get benchmark for each of them. We tweak the models by parameter tuning and ensemble. Compared to benchmark, we could know how much increase those new models got.\n",
    "\n",
    "\n",
    "### Evaluation Metrics\n",
    "The cost need be predict is continuous variable. For a regression problem, we usually use Mean Square Error(MSE) or Mean Absolute Error(MAE) as metric. According to the competetion evalution criteria, MAE is used. We are going to build models to minimize MAE.\n",
    "\n",
    "### Project Design\n",
    "The project mainly has the workflow:\n",
    "- Expolorary data analysis.\n",
    "- Feature engineering.\n",
    "- Split the data into training set and validation set (cross validation). Building machine learning models, tuning parameters.\n",
    "    - The model includes regression, glmnet, random forest, gradient boosting tree, neural network, etc.\n",
    "- Compare and pick the best model for each method. Ensemble/Stack best single models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
